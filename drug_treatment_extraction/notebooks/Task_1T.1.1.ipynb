{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script finds matches to sets of words in tokenized datasets.  It can run over titles, abstracts, body text, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunTitle    = True\n",
    "RunAbstract = True\n",
    "RunBody     = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import scispacy\n",
    "import spacy\n",
    "nlp=spacy.load(\"en_core_sci_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all the files in these paths \n",
    "Paths=[\"./CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset/\",\"./CORD-19-research-challenge/comm_use_subset/comm_use_subset/\",\"./CORD-19-research-challenge/biorxiv_medrxiv/biorxiv_medrxiv/\",\"./CORD-19-research-challenge/custom_license/custom_license/\"]\n",
    "#Paths=[\"./CORD-19-research-challenge/biorxiv_medrxiv/biorxiv_medrxiv/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions determine what blocks are pulled from the paper for matching\n",
    "def TitleBlocks(paper):\n",
    "    return([{'text':paper['metadata']['title']}])\n",
    "\n",
    "def AbstractBlocks(paper):\n",
    "    return(paper['abstract'])\n",
    "\n",
    "def BodyBlocks(paper):\n",
    "    return(paper['body_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function finds matching lemmas and notes positions of\n",
    "# occurence in the relevant json block\n",
    "def PullMentions(Paths, BlockSelector,SecName, Words):\n",
    "    Positions=[]\n",
    "    FoundWords=[]\n",
    "    Section=[]\n",
    "    BlockID=[]\n",
    "    BlockText=[]\n",
    "    PaperID=[]\n",
    "    \n",
    "    tokenized_words=[]\n",
    "    for w in Words:\n",
    "        tokenized_words.append(nlp(w)[0].lemma_)\n",
    "    for Path in Paths:\n",
    "        print(Path)\n",
    "\n",
    "        Files=os.listdir(Path)\n",
    "        for p in Files:\n",
    "\n",
    "            readfile=open(Path+p,'r')\n",
    "            paper=json.load(readfile)\n",
    "            Blocks=BlockSelector(paper)\n",
    "\n",
    "            for b in range(0,len(Blocks)):\n",
    "                text=nlp(Blocks[b]['text'])\n",
    "\n",
    "                for t in text:\n",
    "                    for w in tokenized_words:\n",
    "                        if(w == t.lemma_):\n",
    "                            Section.append(SecName)\n",
    "                            FoundWords.append(w)\n",
    "                            Positions.append(t.idx)\n",
    "                            BlockText.append(Blocks[b]['text'])\n",
    "                            BlockID.append(b)\n",
    "                            PaperID.append(p[:-5])\n",
    "    return {'sha':PaperID,'blockid':BlockID,'word':FoundWords,'sec':Section,'pos':Positions,'block':BlockText}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to get treatment words\n",
    "def ExtractToCSV(Words,Filename):\n",
    "\n",
    "    DataDicts=[]\n",
    "    if(RunTitle): \n",
    "        DataDicts.append(PullMentions(Paths, TitleBlocks,    \"title\",    Words))\n",
    "    if(RunAbstract):\n",
    "        DataDicts.append(PullMentions(Paths, AbstractBlocks, \"abstract\", Words))\n",
    "    if(RunBody):\n",
    "        DataDicts.append(PullMentions(Paths, BodyBlocks,     \"body\",     Words))\n",
    "\n",
    "    SummedDictionary=DataDicts[0]\n",
    "    for k in DataDicts[0].keys():\n",
    "        for d in DataDicts:\n",
    "            SummedDictionary[k]=SummedDictionary[k]+d[k]\n",
    "\n",
    "    dat=pd.DataFrame(SummedDictionary)\n",
    "    dat.to_csv(Filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset/\n",
      "./CORD-19-research-challenge/comm_use_subset/comm_use_subset/\n",
      "./CORD-19-research-challenge/biorxiv_medrxiv/biorxiv_medrxiv/\n",
      "./CORD-19-research-challenge/custom_license/custom_license/\n",
      "./CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset/\n",
      "./CORD-19-research-challenge/comm_use_subset/comm_use_subset/\n",
      "./CORD-19-research-challenge/biorxiv_medrxiv/biorxiv_medrxiv/\n",
      "./CORD-19-research-challenge/custom_license/custom_license/\n",
      "./CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset/\n",
      "./CORD-19-research-challenge/comm_use_subset/comm_use_subset/\n",
      "./CORD-19-research-challenge/biorxiv_medrxiv/biorxiv_medrxiv/\n",
      "./CORD-19-research-challenge/custom_license/custom_license/\n",
      "./CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset/\n",
      "./CORD-19-research-challenge/comm_use_subset/comm_use_subset/\n"
     ]
    }
   ],
   "source": [
    "Words=['treat','treatment' 'alleviate', 'manage', 'suppress','suppression', 'prescribe','therapy','cure','remedy', 'therapeutic','administer']\n",
    "ExtractToCSV(Words, \"TitleAbstractMatches_therapies.csv\")\n",
    "\n",
    "Words=[\"naproxen\",\"clarithromycin\",\"chloroquine\",\"kaletra\",\"Favipiravir\",\"Avigan\",'hydroxychloroquine','baricitinib']\n",
    "ExtractToCSV(Words, \"TitleAbstractMatches_drugs.csv\")\n",
    "\n",
    "Words=[\"COVID-19\", \"Coronavirus\", \"Corona\", \"2019-nCoV\", \"SARS-CoV\",]\n",
    "ExtractToCSV(Words, \"TitleAbstractMatches_virusnames.csv\")\n",
    "\n",
    "Words=[\"vitro\", \"vivo\", \"in-vitro\", \"in-vivo\", \"mouse\",\"mice\",\"clinial\",\"human\",\"computational\",\"vertical\",\"horizontal\",\"theoretical\",\"simulation\"]\n",
    "ExtractToCSV(Words, \"TitleAbstractMatches_exptypes.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
